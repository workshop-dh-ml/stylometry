{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "moved-natural",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import requests\n",
    "from io import BytesIO\n",
    "import zipfile\n",
    "# \n",
    "# https://programminghistorian.org/en/lessons/introduction-to-stylometry-with-python\n",
    "url = 'https://github.com/programminghistorian/ph-submissions/raw/gh-pages/assets/introduction-to-stylometry-with-python/stylometry-federalist.zip'\n",
    "zipped = requests.get(url).content\n",
    "fp = BytesIO(zipped)\n",
    "zfile = zipfile.ZipFile(fp, \"r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "attempted-horse",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = {\n",
    "    'Madison': [10, 14, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48],\n",
    "    'Hamilton': [1, 6, 7, 8, 9, 11, 12, 13, 15, 16, 17, 21, 22, 23, 24,\n",
    "                 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 59, 60,\n",
    "                 61, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77,\n",
    "                 78, 79, 80, 81, 82, 83, 84, 85],\n",
    "    'Jay': [2, 3, 4, 5],\n",
    "    'Shared': [18, 19, 20],\n",
    "    'Disputed': [49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 62, 63],\n",
    "    'TestCase': [64]\n",
    "}\n",
    "\n",
    "dataset = []\n",
    "for label, indices in labels.items():\n",
    "    for index in indices:\n",
    "        dataset.append({\n",
    "            \"label\": label,\n",
    "            \"text\": zfile.open(f\"data/federalist_{index}.txt\").read().decode('utf-8')\n",
    "        })\n",
    "dataset = pd.DataFrame(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "obvious-cornell",
   "metadata": {},
   "source": [
    "## Ex 1: \n",
    "* create equal sized chunks of the text as individual samples\n",
    "* split into train/test/exploration data set `X_train`, `X_test`, ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "smart-stationery",
   "metadata": {},
   "source": [
    "### Chunking & Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "reserved-volunteer",
   "metadata": {},
   "outputs": [],
   "source": [
    "# chunking (200 words per chunk)\n",
    "    # Split the input text into chunks, where # each chunk contains N words \n",
    "\n",
    "def tokenizer(input_data):     # creates words from strings\n",
    "    return input_data.split(' ')     \n",
    "\n",
    "def chunker(ll):\n",
    "    result = [[]]\n",
    "    count = 0\n",
    "    \n",
    "    for item in ll:\n",
    "        if len(result[-1]) >= 200:\n",
    "            result.append([])\n",
    "            \n",
    "        result[-1].append(item)\n",
    "        count += 1\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "dramatic-valuable",
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply tokenizer & chunker\n",
    "\n",
    "new_text = []\n",
    "\n",
    "for _,row in dataset.iterrows():\n",
    "    \n",
    "    tokenized = tokenizer(row.text)\n",
    "    chunks = chunker(tokenized)\n",
    "    \n",
    "    for chunk in chunks:\n",
    "        new_text.append({\n",
    "            'label' : row.label,\n",
    "            'text' : chunk\n",
    "        })\n",
    "        \n",
    "new_df = pd.DataFrame(new_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "inside-unemployment",
   "metadata": {},
   "source": [
    "### Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "derived-receiver",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Madison</td>\n",
       "      <td>[, 10\\n\\nThe, Same, Subject, Continued, (The, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Madison</td>\n",
       "      <td>[of, public, and, private, faith,, and, of, pu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Madison</td>\n",
       "      <td>[actuated, by, some\\ncommon, impulse, of, pass...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Madison</td>\n",
       "      <td>[a, reciprocal, influence, on, each, other;, a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Madison</td>\n",
       "      <td>[fall, into, mutual\\nanimosities,, that, where...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     label                                               text\n",
       "0  Madison  [, 10\\n\\nThe, Same, Subject, Continued, (The, ...\n",
       "1  Madison  [of, public, and, private, faith,, and, of, pu...\n",
       "2  Madison  [actuated, by, some\\ncommon, impulse, of, pass...\n",
       "3  Madison  [a, reciprocal, influence, on, each, other;, a...\n",
       "4  Madison  [fall, into, mutual\\nanimosities,, that, where..."
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train Test Split\n",
    "\n",
    "test = new_df[new_df.label=='TestCase']\n",
    "test.head()\n",
    "\n",
    "trainevalu = new_df[new_df.label!='TestCase']\n",
    "trainevalu.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "united-dealing",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorization\n",
    "\n",
    "import sklearn.feature_extraction\n",
    "\n",
    "def noop(X):\n",
    "    return X\n",
    "\n",
    "vectorizer = sklearn.feature_extraction.text.CountVectorizer(tokenizer=noop, preprocessor=noop)\n",
    "\n",
    "new_df.text = vectorizer.fit_transform(new_df.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "international-spell",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST DATA \n",
    "\n",
    "test = new_df[new_df.label=='TestCase']\n",
    "trainevalu = new_df[new_df.label!='TestCase']\n",
    "\n",
    "X_test = test.text\n",
    "y_test = test.label\n",
    "\n",
    "# TRAIN & EVALUATION DATA\n",
    "# test train split with sklearn (stratified = splits according to labels for equal representation)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_eval, y_train, y_eval = train_test_split(trainevalu.text, \n",
    "                                                    trainevalu.label,\n",
    "                                                    stratify=trainevalu.label, \n",
    "                                                    test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "incomplete-equipment",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.hist(y_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "square-pathology",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.hist(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "color-dallas",
   "metadata": {},
   "source": [
    "## Ex 2:\n",
    "* implement Burrows' Delta or other variants of stylometric methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "working-administration",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BurrowsDelta:\n",
    "    \n",
    "    def __init__(self, num_words=500):\n",
    "        self.num_words = num_words\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        \n",
    "        #import pdb;pdb.set_trace()\n",
    "        \n",
    "        self.chosen_words = np.ravel(X.sum(axis=0)).argsort()[::-1][:self.num_words]\n",
    "        sX = X.T[self.chosen_words].toarray()\n",
    "    \n",
    "        ### YOUR CODE BELOW\n",
    "        \n",
    "        self.mea_word = sX.mean(axis=1)\n",
    "        self.std_word = sX.std(axis=1)\n",
    "        self.z_scores = ((sX.T - self.mea_word) / self.std_word).T\n",
    "        \n",
    "        ### YOUR CODE ABOVE\n",
    "        self.y = np.array(y)\n",
    "            \n",
    "    def predict(self, X):\n",
    "        ### YOUR CODE BELOW\n",
    "\n",
    "        sX = X.T[self.chosen_words].toarray()\n",
    "        new_z_scores = ((sX.T - self.mea_word) / self.std_word).T\n",
    "        \n",
    "        ### YOUR CODE ABOVE\n",
    "        \n",
    "        dists = 1-cdist(new_z_scores.T, self.z_scores.T)\n",
    "        \n",
    "        return self.y[dists.argmax(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "intense-amount",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'sum'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-204-6c9e52ce96ca>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBurrowsDelta\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_eval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassification_report\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_eval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-200-20070a36b00c>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0;31m#import pdb;pdb.set_trace()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchosen_words\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margsort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_words\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0msX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchosen_words\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'sum'"
     ]
    }
   ],
   "source": [
    "clf = BurrowsDelta()\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_eval)\n",
    "\n",
    "print(classification_report(np.array(y_eval), y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
